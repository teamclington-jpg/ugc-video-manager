# Test Agent Configuration

## ðŸ¤– Test Agent Role
ìžë™í™”ëœ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° í’ˆì§ˆ ë³´ì¦ì„ ë‹´ë‹¹í•˜ëŠ” ì „ë¬¸ ì—ì´ì „íŠ¸

## ðŸ“‹ Test Agent Responsibilities

### 1. Unit Testing
- ê°œë³„ ëª¨ë“ˆ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
- Mock ê°ì²´ í™œìš©
- ì—£ì§€ ì¼€ì´ìŠ¤ ê²€ì¦

### 2. Integration Testing  
- ëª¨ë“ˆ ê°„ í†µí•© í…ŒìŠ¤íŠ¸
- API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
- ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ í…ŒìŠ¤íŠ¸

### 3. Performance Testing
- ë¶€í•˜ í…ŒìŠ¤íŠ¸ (200ê°œ ë™ì‹œ ì²˜ë¦¬)
- ì‘ë‹µ ì‹œê°„ ì¸¡ì •
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§

### 4. Security Testing
- ì¸ì¦/ì¸ê°€ í…ŒìŠ¤íŠ¸
- SQL Injection ë°©ì§€ ê²€ì¦
- ì•”í˜¸í™” ê²€ì¦

## ðŸ› ï¸ Test Environment Setup

### Required Tools
```bash
# Test dependencies
pytest>=7.0.0
pytest-asyncio>=0.21.0
pytest-cov>=4.0.0
pytest-mock>=3.10.0
httpx>=0.24.0  # For API testing
faker>=18.0.0  # For test data generation
```

### Test Database
- Separate test database in Supabase
- Automatic setup/teardown
- Test data seeding

## ðŸ“‚ Test Structure
```
test_environment/
â”œâ”€â”€ unit_tests/
â”‚   â”œâ”€â”€ test_video_watcher.py
â”‚   â”œâ”€â”€ test_video_analyzer.py
â”‚   â”œâ”€â”€ test_channel_matcher.py
â”‚   â”œâ”€â”€ test_seo_generator.py
â”‚   â”œâ”€â”€ test_product_matcher.py
â”‚   â”œâ”€â”€ test_queue_manager.py
â”‚   â””â”€â”€ test_limit_tracker.py
â”œâ”€â”€ integration_tests/
â”‚   â”œâ”€â”€ test_api_endpoints.py
â”‚   â”œâ”€â”€ test_database_operations.py
â”‚   â”œâ”€â”€ test_workflow_complete.py
â”‚   â””â”€â”€ test_external_services.py
â”œâ”€â”€ performance_tests/
â”‚   â”œâ”€â”€ test_concurrent_processing.py
â”‚   â”œâ”€â”€ test_api_load.py
â”‚   â””â”€â”€ test_memory_usage.py
â”œâ”€â”€ security_tests/
â”‚   â”œâ”€â”€ test_authentication.py
â”‚   â”œâ”€â”€ test_encryption.py
â”‚   â””â”€â”€ test_sql_injection.py
â”œâ”€â”€ fixtures/
â”‚   â”œâ”€â”€ sample_videos/
â”‚   â”œâ”€â”€ mock_data.py
â”‚   â””â”€â”€ test_config.py
â””â”€â”€ reports/
    â”œâ”€â”€ coverage/
    â””â”€â”€ performance/
```

## ðŸŽ¯ Test Commands

### Run All Tests
```bash
pytest test_environment/ -v
```

### Run Specific Category
```bash
# Unit tests only
pytest test_environment/unit_tests/ -v

# Integration tests
pytest test_environment/integration_tests/ -v

# With coverage report
pytest test_environment/ --cov=src --cov-report=html
```

### Performance Testing
```bash
# Load testing
python test_environment/performance_tests/test_concurrent_processing.py

# Memory profiling
python -m memory_profiler test_environment/performance_tests/test_memory_usage.py
```

## ðŸ“Š Test Metrics

### Coverage Goals
- Unit Tests: >80% coverage
- Integration Tests: >70% coverage
- Critical paths: 100% coverage

### Performance Benchmarks
- API Response: <200ms (p95)
- Video Processing: <5s per video
- Database queries: <100ms

### Success Criteria
- âœ… All unit tests pass
- âœ… Integration tests pass
- âœ… Performance benchmarks met
- âœ… Security tests pass
- âœ… No memory leaks detected

## ðŸ”„ CI/CD Integration

### GitHub Actions Workflow
```yaml
name: Test Suite

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-test.txt
      - name: Run tests
        run: pytest test_environment/ -v --cov=src
      - name: Upload coverage
        uses: codecov/codecov-action@v3
```

## ðŸ“ Test Documentation

### Test Case Template
```python
"""
Test ID: TC-001
Module: VideoWatcher
Function: detect_new_video
Description: Verify new video detection in watch folder
Prerequisites: Watch folder exists and is accessible
"""

@pytest.mark.asyncio
async def test_detect_new_video():
    # Arrange
    watcher = VideoWatcher("/test/folder")
    test_video = create_test_video()
    
    # Act
    result = await watcher.detect_new_video(test_video)
    
    # Assert
    assert result.detected == True
    assert result.file_path == test_video.path
```

## ðŸš¨ Error Reporting

### Test Failure Format
```
FAILED: test_video_analyzer.py::test_gemini_api_connection
Reason: API key invalid or expired
Action: Check GEMINI_API_KEY in .env.test
Priority: HIGH
```

## ðŸ”§ Mock Services

### Gemini API Mock
```python
class MockGeminiAPI:
    async def analyze_video(self, video_path):
        return {
            "products": ["Product A", "Product B"],
            "category": "technology",
            "confidence": 0.95
        }
```

### Supabase Mock
```python
class MockSupabase:
    async def insert(self, table, data):
        return {"id": "mock-uuid", **data}
```

## ðŸŽ¯ Test Agent Workflow

1. **Environment Check**
   - Verify test database connection
   - Check API keys availability
   - Ensure test folders exist

2. **Pre-test Setup**
   - Clear test database
   - Seed test data
   - Initialize mocks

3. **Test Execution**
   - Run tests by category
   - Collect metrics
   - Generate reports

4. **Post-test Cleanup**
   - Remove test files
   - Clear database
   - Archive reports

5. **Result Analysis**
   - Coverage analysis
   - Performance metrics
   - Security vulnerabilities

## ðŸ“ˆ Continuous Improvement

### Weekly Tasks
- Review failed tests
- Update test cases
- Improve coverage
- Optimize slow tests

### Monthly Tasks
- Security audit
- Performance baseline update
- Test infrastructure review
- Documentation update

---

*Test Agent v1.0 - Ensuring Quality Through Automation*